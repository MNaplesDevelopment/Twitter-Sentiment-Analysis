{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sLU_BZbdkeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Written by Michael Naples 4/10/18"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTsA0EUhckD9",
        "colab_type": "code",
        "outputId": "338b04f7-b454-462e-8f72-29a3e71522c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#Trained on a Tesla K80 (2496 CUDA cores @ 3.7GHz - 12GB) - Thanks Google\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 10 20:36:49 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXpLEM5891lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, CuDNNLSTM, Embedding, Bidirectional, Dropout\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koHoonffdAwT",
        "colab_type": "code",
        "outputId": "87c62974-3316-4c59-b544-50925ede77d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import sys\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "print(sys.version)\n",
        "print()\n",
        "print(tf.VERSION)\n",
        "print()\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.7 (default, Oct 22 2018, 11:32:17) \n",
            "[GCC 8.2.0]\n",
            "\n",
            "1.13.1\n",
            "\n",
            "2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MO-k-ZG0Y8d",
        "colab_type": "code",
        "outputId": "a82269d5-cbc8-4312-b8e1-741857482ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip /content/twitter_embs.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/twitter_embs.zip\n",
            "  inflating: twitter_embs.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyXm_KZe-Gwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('training.pkl', 'rb') as handle:\n",
        "    training = pickle.load(handle)\n",
        "with open('labels.pkl', 'rb') as handle:\n",
        "    labels = pickle.load(handle)\n",
        "with open('twitter_embs.txt', 'r') as handle:\n",
        "    embeddings = handle.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA3GY6UauZVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = np.asarray(training)\n",
        "labels = np.asarray(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAqIZ1_ousVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = {}  # Dictionary of all unique words from every tweet\n",
        "for sent in training:\n",
        "  for word in sent:\n",
        "    if word not in words:\n",
        "      words[word] = 0\n",
        "    else:\n",
        "      words[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFoy8gvnJq-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embs = {}  # Mapping from each word to its embedding\n",
        "for i, line in enumerate(embeddings):\n",
        "    split = line.split()\n",
        "    word = split[0]\n",
        "    if word in words or word == '<unknown>':\n",
        "        embedding = np.array([float(val) for val in split[1:]])\n",
        "        embs[word] = embedding\n",
        "del embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EopT_ArrKpGr",
        "colab_type": "code",
        "outputId": "73ca87ed-8afd-46e5-ccc6-89e34c967304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "missing_words = {}  # Dictionary of every word without an embedding, use the <unknown> token fo these.\n",
        "words['<unknown>'] = 0\n",
        "for word in words.keys():\n",
        "  if word not in embs:\n",
        "    missing_words[word] = 0\n",
        "print(len(missing_words))\n",
        "print(len(words))\n",
        "print(len(embs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "409763\n",
            "503776\n",
            "94013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPri3xif_Iqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = []  # Embedding matrix the network uses\n",
        "int_to_word = []       # Index to word\n",
        "word_to_int = {}       # word to index\n",
        "i = 0\n",
        "for word, emb in embs.items():\n",
        "    embedding_matrix.append(emb)\n",
        "    int_to_word.append(word)\n",
        "    word_to_int[word] = i\n",
        "    i += 1\n",
        "    \n",
        "#embedding_matrix.append(np.zeros(200))\n",
        "embedding_matrix = np.asarray(embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL6BTEELLab4",
        "colab_type": "code",
        "outputId": "4d39add2-1c9b-4b5d-a66a-5395166326d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ndx = word_to_int['cool']  # Sanity check\n",
        "print(ndx)\n",
        "print(int_to_word[ndx])\n",
        "print(np.array_equal(embs['cool'], embedding_matrix[ndx]))\n",
        "print(embedding_matrix.shape) # (number of words, embedding size) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "488\n",
            "cool\n",
            "True\n",
            "(94013, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTSFECfJ_LDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(training.shape[0]):  # Im pretty sure this is pointless\n",
        "    string = ''\n",
        "    for j in range(len(training[i])):\n",
        "        string += training[i][j] + ' '\n",
        "    training[i] = string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6SreMUB_Xtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = training[training.shape[0]-50000:]  # Chop off 50,000 for testing\n",
        "test_labels = labels[labels.shape[0]-50000:]\n",
        "train_data = training[:training.shape[0]-50000]\n",
        "train_labels = labels[:labels.shape[0]-50000]\n",
        "\n",
        "num_words = len(embs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfjsFYzU_aEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_strings(data, words_found=None, words_missing=None):  # Convert each word to its index into the embedding matrix (tokens)\n",
        "  data_tokens = []\n",
        "  for i in range(data.shape[0]):  \n",
        "      data_tokens.append([])\n",
        "      for word in data[i].split():\n",
        "          if word in embs:\n",
        "              data_tokens[i].append(word_to_int[word])\n",
        "              if words_found is not None:\n",
        "                words_found += 1\n",
        "          else:\n",
        "              data_tokens[i].append(word_to_int['<unknown>'])  # Use the <unknown> token for words without an embedding\n",
        "              if words_missing is not None:\n",
        "                words_missing += 1\n",
        "  if words_found is not None and words_missing is not None:\n",
        "    return data_tokens, words_found, words_missing\n",
        "  return data_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e13JRmJ2eYzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words_found = 0\n",
        "num_words_missing = 0\n",
        "\n",
        "train_data_tokens, num_words_found, num_words_missing = tokenize_strings(train_data, num_words_found, num_words_missing)\n",
        "test_data_tokens, num_words_found, num_words_missing = tokenize_strings(test_data, num_words_found, num_words_missing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I1DDiUpvNEL",
        "colab_type": "code",
        "outputId": "ad4b73cf-af97-45b1-abaa-306257d64b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Number of words embedding found: %d\" % num_words_found)\n",
        "print(\"Number of words embedding missing: %d\" % num_words_missing)\n",
        "print('Percent of unknown words: {:.2%}'.format(num_words_missing / num_words_found))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words embedding found: 16453626\n",
            "Number of words embedding missing: 154764\n",
            "Percent of unknown words: 0.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS3_5IDd_a88",
        "colab_type": "code",
        "outputId": "32c5da4d-8918-4054-fd00-94f7666cf3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_data_tokens[0])\n",
        "print(test_data_tokens[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 7, 23, 1275, 45, 11587, 26, 50, 286, 13, 13, 1387, 771, 8]\n",
            "[26, 1258, 69052, 603, 1, 1, 201, 928, 1171, 3570, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjhwE4QA_c3M",
        "colab_type": "code",
        "outputId": "2475d967-f920-40d8-d755-8a1eaba7cf83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def tokens_to_string(tokens):  # Convert tokens back into their sting value\n",
        "    words = [int_to_word[token] for token in tokens if token != 0]\n",
        "    text = \" \".join(words)\n",
        "    return text\n",
        "print(train_data_tokens[0])\n",
        "print(tokens_to_string(train_data_tokens[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 7, 23, 1275, 45, 11587, 26, 50, 286, 13, 13, 1387, 771, 8]\n",
            "<url> - aww so toro is your baby ? ? soo sweet !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0dKKDJ1_hIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = [len(tokens) for tokens in train_data_tokens + test_data_tokens]\n",
        "num_tokens = np.asarray(num_tokens)\n",
        "max_tokens = np.max(num_tokens)  # Find the longest tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dqiJ8CVW2qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_tokens += 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ib2CA4DCND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad each example with 0's so they all match the length of the longest tweet\n",
        "# In TensorFlow all sequences must be the same length\n",
        "pad = 'pre'\n",
        "train_data_pad = pad_sequences(train_data_tokens, maxlen=max_tokens,\n",
        "                              padding=pad, truncating=pad)\n",
        "test_data_pad = pad_sequences(test_data_tokens, maxlen=max_tokens,\n",
        "                             padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJPJ7vJDDGO7",
        "colab_type": "code",
        "outputId": "f666c564-97a8-4345-f74e-9bbd3449a3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_data_pad.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(949985, 144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COtIx2LxDMAE",
        "colab_type": "code",
        "outputId": "37092223-8151-4d02-9e90-1bf783dbf138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model = Sequential()  # Create the network's computation graph, Bidirectional-LSTM-RNN\n",
        "model.add(Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                   output_dim=embedding_matrix.shape[1],\n",
        "                   input_length=max_tokens,\n",
        "                   weights=[embedding_matrix],\n",
        "                   trainable=False,\n",
        "                   name='embedding_layer'))\n",
        "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(CuDNNLSTM(32, return_sequences=True)))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Bidirectional(CuDNNLSTM(16)))\n",
        "model.add(Dropout(0.1))\n",
        "#model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(lr=1e-3)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',   # Compile the network\n",
        "             optimizer=optimizer,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI4T_Nz0DQ0M",
        "colab_type": "code",
        "outputId": "313e785b-aeb9-4bec-bb42-82d46ee1c7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_layer (Embedding)  (None, 144, 200)          18802600  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 144, 128)          136192    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 144, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 144, 64)           41472     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 144, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 32)                10496     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 18,990,793\n",
            "Trainable params: 188,193\n",
            "Non-trainable params: 18,802,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnyA4gGqDS7k",
        "colab_type": "code",
        "outputId": "4b07907d-fce5-4a81-f695-583991038083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# Train the model, about 50,000 examples are set aside for validation\n",
        "#%%time   \n",
        "model.fit(train_data_pad, train_labels,\n",
        "         validation_split=0.05, epochs=10, batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 902485 samples, validate on 47500 samples\n",
            "Epoch 1/10\n",
            "902485/902485 [==============================] - 139s 154us/step - loss: 0.4486 - acc: 0.7877 - val_loss: 0.4205 - val_acc: 0.8057\n",
            "Epoch 2/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3963 - acc: 0.8205 - val_loss: 0.3872 - val_acc: 0.8246\n",
            "Epoch 3/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3782 - acc: 0.8305 - val_loss: 0.3786 - val_acc: 0.8318\n",
            "Epoch 4/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3667 - acc: 0.8366 - val_loss: 0.3696 - val_acc: 0.8355\n",
            "Epoch 5/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3575 - acc: 0.8416 - val_loss: 0.3639 - val_acc: 0.8385\n",
            "Epoch 6/10\n",
            "902485/902485 [==============================] - 138s 153us/step - loss: 0.3501 - acc: 0.8451 - val_loss: 0.3604 - val_acc: 0.8403\n",
            "Epoch 7/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3432 - acc: 0.8489 - val_loss: 0.3582 - val_acc: 0.8429\n",
            "Epoch 8/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3371 - acc: 0.8522 - val_loss: 0.3559 - val_acc: 0.8437\n",
            "Epoch 9/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3319 - acc: 0.8547 - val_loss: 0.3569 - val_acc: 0.8419\n",
            "Epoch 10/10\n",
            "902485/902485 [==============================] - 137s 152us/step - loss: 0.3264 - acc: 0.8574 - val_loss: 0.3620 - val_acc: 0.8414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f59f2e941d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oVBQhcADWJ0",
        "colab_type": "code",
        "outputId": "8a4a3484-c724-4890-b6b2-025878855ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Evaluate model accuracy on test data\n",
        "result = model.evaluate(test_data_pad, test_labels)\n",
        "print(\"accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 27s 536us/step\n",
            "accuracy: 84.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjp94czGZiEN",
        "colab_type": "code",
        "outputId": "fa780647-342c-4c86-907e-de9b43fc236e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Test on individual tweets\n",
        "tweet = \"so bored at work <number> and a half days til wichita falls\"\n",
        "token_tweet = tokenize_strings(np.asarray([tweet]))\n",
        "tweet_pad = pad_sequences(token_tweet, maxlen=max_tokens,\n",
        "                              padding=pad, truncating=pad)\n",
        "result = model.evaluate(tweet_pad, [0])\n",
        "if result[1] == 1:\n",
        "  print('negative')\n",
        "else:\n",
        "  print('positive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 15ms/step\n",
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylDUWQ-5KRwL",
        "colab_type": "code",
        "outputId": "187cacbb-8c37-48a6-ba45-64d73736b3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_json = model.to_json()  # Save model to disk\n",
        "with open(\"model8402.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "model.save_weights(\"model8402.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIltZjoid5WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMCLVWJ4d5ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp2bgO7HUNW9",
        "colab_type": "code",
        "outputId": "9e1852cd-52c1-457b-9a73-979a7a643a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import model_from_json  # Load model from files\n",
        "json_file = open('model8402.json', 'r')\n",
        "model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(model_json)\n",
        "loaded_model.load_weights(\"model8402.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "optimizer = Adam(lr=1e-3)\n",
        "loaded_model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizer,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oIGPsh1ghDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test1.pkl', 'rb') as handle:\n",
        "    test1 = pickle.load(handle)\n",
        "with open('labels1.pkl', 'rb') as handle:\n",
        "    labels1 = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6kbjbzcgrLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1 = np.asarray(test1)\n",
        "for i in range(test1.shape[0]):  # Im pretty sure this is pointless\n",
        "    string = ''\n",
        "    for j in range(len(test1[i])):\n",
        "        string += test1[i][j] + ' '\n",
        "    test1[i] = string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snmhRCgChAMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1_tokens = tokenize_strings(test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mgmUj8ghLm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1_data_pad = pad_sequences(test1_tokens, maxlen=max_tokens,\n",
        "                              padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL9Z6u3ZhWyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = loaded_model.predict(test1_data_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx2Jgr_DhvzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test1_out.txt', 'w+') as f:\n",
        "  for i in range(len(results)):\n",
        "    if results[i] > .5:\n",
        "      f.write(labels1[i] + '\\t\\t' + '+' + '\\n')\n",
        "    else:\n",
        "      f.write(labels1[i] + '\\t\\t' + '-' + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9a4usyF3Dwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}